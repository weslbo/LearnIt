{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AZ-204: 03 Develop solutions that use Blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../utils')\n",
    "import ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "➡️ Answers generated using AI, and grounded in the learn module. Mistakes are possible. Check important info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Azure Blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://learn.microsoft.com/en-us/training/modules/explore-azure-blob-storage/1-introduction\n",
      "https://learn.microsoft.com/en-us/training/modules/explore-azure-blob-storage/2-blob-storage-overview\n",
      "https://learn.microsoft.com/en-us/training/modules/explore-azure-blob-storage/3-blob-storage-resources\n",
      "https://learn.microsoft.com/en-us/training/modules/explore-azure-blob-storage/4-blob-storage-security\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " 'https://learn.microsoft.com/en-us/training/modules/explore-azure-blob-storage/\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%learn\n",
    "https://learn.microsoft.com/en-us/training/modules/explore-azure-blob-storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Azure Blob Storage is Microsoft's cloud-based object storage solution designed to store large amounts of unstructured data, such as text or binary data. It's versatile, suitable for serving images or documents, streaming media, storing files for distributed access, and more. It offers different types of storage accounts and access tiers to optimize cost and performance based on usage patterns."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What is Azure Blob Storage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "From a developer's perspective, choosing Azure Blob Storage over regular disks or fileshares offers several advantages:\n",
       "\n",
       "1. **Scalability**: Blob Storage can handle massive amounts of unstructured data and scales automatically, crucial for applications with fluctuating storage demands.\n",
       "\n",
       "2. **Cost-Effectiveness**: With various access tiers (Hot, Cool, Cold, Archive), you can optimize costs based on how frequently you access your data.\n",
       "\n",
       "3. **Global Access**: Data in Blob Storage can be accessed globally via HTTP/HTTPS, making it ideal for web applications that serve content to users worldwide.\n",
       "\n",
       "4. **Integration and APIs**:\n",
       "   - **Blob Storage**: Offers REST APIs, Azure SDKs, Azure CLI, and PowerShell, facilitating easier integration with cloud-native applications.\n",
       "   - **Disks/Fileshares**: Typically accessed via OS-level file APIs or SMB/NFS protocols, suitable for more traditional, on-premises-like applications.\n",
       "\n",
       "5. **Data Redundancy and Security**: Blob Storage provides various redundancy options and built-in encryption features, ensuring data durability and security.\n",
       "\n",
       "6. **Flexible Data Management**: Blobs can be easily managed individually, allowing for more granular control over data operations compared to traditional disks.\n",
       "\n",
       "Overall, Azure Blob Storage offers a more flexible, scalable, and cost-effective solution tailored to cloud-native applications compared to traditional disk storage or fileshares."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Why would I choose Blob Storage over regular disks or fileshares? Look at this from a developers perspective. Compare also the API's one would use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can access this from anywhere on the world (HTTP)\n",
    "- Disaster recovery over multiple regions\n",
    "- Authorize different access\n",
    "- CHEAPER\n",
    "- We don't want to handle the infrastructure\n",
    "\n",
    "App:code (c#)\n",
    "-> Machine (os:Windows)\n",
    "-> System.IO.File.WriteText(c:\\file.txt)   <>  Blob Storage SDK\n",
    "-> OS API calls (Win32)\n",
    "\n",
    "-> Azure App Service\n",
    "-> Disk by default does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A blob in Azure Blob Storage is a type of object storage that holds unstructured data. Azure supports three types of blobs:\n",
       "\n",
       "1. **Block Blobs**: Used for storing text and binary data, and optimized for streaming and storing large files. They can store up to about 190.7 TiB.\n",
       "   \n",
       "2. **Append Blobs**: Similar to block blobs but optimized for append operations, making them ideal for logging data.\n",
       "\n",
       "3. **Page Blobs**: Designed for random access and used for storing virtual hard drive (VHD) files, with a size limit of 8 TB."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What is a blob?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLOB: **B**inary **L**arge **Ob**ject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To create a storage account using Azure CLI, you can use the following command:\n",
       "\n",
       "```bash\n",
       "az storage account create --name <storage-account-name> --resource-group <resource-group-name> --location <location> --sku Standard_LRS\n",
       "```\n",
       "\n",
       "Replace `<storage-account-name>`, `<resource-group-name>`, and `<location>` with your desired storage account name, resource group, and location.\n",
       "\n",
       "**Requirements for the Storage Account Name**:\n",
       "- Must be between 3 and 24 characters long.\n",
       "- Can contain only lowercase letters and numbers.\n",
       "- Must be unique within Azure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "How do I create a storage account with Azure CLI? What are the requirements for the name of the storage account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, OneDrive is built on top of Azure Blob Storage. Blob Storage provides the scalable, secure, and reliable storage infrastructure necessary for OneDrive to store and manage large volumes of user data, such as documents and media files."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Is OneDrive build on top of Blob Storage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Here's a table comparing key management options for Azure Storage encryption:\n",
       "\n",
       "| Key Management Parameter   | Microsoft-Managed Keys | Customer-Managed Keys       | Customer-Provided Keys     |\n",
       "|----------------------------|------------------------|-----------------------------|----------------------------|\n",
       "| Encryption/Decryption Ops  | Azure                  | Azure                       | Azure                      |\n",
       "| Azure Storage Services     | All                    | Blob Storage, Azure Files   | Blob Storage               |\n",
       "| Key Storage                | Microsoft Key Store    | Azure Key Vault or Key Vault HSM | Customer's Own Key Store   |\n",
       "| Key Rotation Responsibility| Microsoft              | Customer                    | Customer                   |\n",
       "| Key Control                | Microsoft              | Customer                    | Customer                   |\n",
       "| Key Scope                  | Account (default), container, or blob | Account (default), container, or blob | N/A                        |\n",
       "\n",
       "This table highlights the differences in key management responsibilities and control between Microsoft-managed keys, customer-managed keys, and customer-provided keys."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Create a table comparing key management options for Azure Storage encryption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Azure Storage provides several services, including:\n",
       "\n",
       "1. **Blob Storage**: For storing unstructured data like text and binary data, such as images, videos, and backups.\n",
       "\n",
       "2. **File Storage (Azure Files)**: Managed file shares accessible via the SMB and NFS protocols, suitable for cloud and on-premises access.\n",
       "\n",
       "3. **Queue Storage**: For message queuing to enable communication between application components in a distributed environment.\n",
       "\n",
       "4. **Table Storage**: A NoSQL key-value store for storing structured data, ideal for rapid development and scalable applications.\n",
       "\n",
       "5. **Disk Storage**: Persistent, high-performance disk storage for Azure Virtual Machines."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What different services are provided by Azure Storage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Azure Blob Storage supports three types of blobs:\n",
       "\n",
       "1. **Block Blobs**: Used for storing text and binary data. They are ideal for large files and can store up to about 190.7 TiB.\n",
       "\n",
       "2. **Append Blobs**: Optimized for append operations, making them suitable for logging and similar scenarios.\n",
       "\n",
       "3. **Page Blobs**: Designed for random access, used primarily for storing virtual hard drive (VHD) files for Azure virtual machines, with a size limit of 8 TB."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What blob types exist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You would choose to create a Page Blob in scenarios where you need:\n",
       "\n",
       "1. **Random Read/Write Access**: Page Blobs are optimized for scenarios that require frequent random read and write operations.\n",
       "\n",
       "2. **Azure Virtual Machine Disks**: They are used to store virtual hard drive (VHD) files and serve as disks for Azure VMs.\n",
       "\n",
       "3. **Large Files with Random Access**: Suitable for applications that require accessing specific sections of large files, such as databases.\n",
       "\n",
       "4. **Snapshot Support**: When you need to take snapshots of the data for backup or recovery purposes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "In what scenarios would I choose to create Page Blob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Choosing the block size for uploading block blobs is important because it affects:\n",
       "\n",
       "1. **Upload Efficiency**: Smaller block sizes can improve upload reliability by allowing individual blocks to be retried if an error occurs, rather than restarting the entire upload.\n",
       "\n",
       "2. **Concurrency**: You can upload multiple blocks concurrently, which can speed up the upload process, especially for large files.\n",
       "\n",
       "3. **Blob Size Limit**: The maximum size of a single block blob is determined by the number of blocks and the size of each block, so choosing an appropriate block size helps manage large file uploads within Azure's limits."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Why do I need to choose the block size for uploading?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The differences between the Azure Storage access tiers—Hot, Cool, Cold, and Archive—are based on cost and access frequency:\n",
       "\n",
       "1. **Hot Tier**:\n",
       "   - **Use Case**: For data accessed frequently.\n",
       "   - **Cost**: Higher storage costs, lower access (read/write) costs.\n",
       "   - **Ideal For**: Active data, such as websites or applications with frequent data access.\n",
       "\n",
       "2. **Cool Tier**:\n",
       "   - **Use Case**: For data that's infrequently accessed and stored for at least 30 days.\n",
       "   - **Cost**: Lower storage costs than Hot, but higher access costs.\n",
       "   - **Ideal For**: Backup, disaster recovery, or data that's not frequently accessed.\n",
       "\n",
       "3. **Cold Tier**:\n",
       "   - **Use Case**: For data that's infrequently accessed and stored for at least 90 days.\n",
       "   - **Cost**: Lower storage costs than Cool, but higher access costs.\n",
       "   - **Ideal For**: Long-term storage where data is rarely accessed.\n",
       "\n",
       "4. **Archive Tier**:\n",
       "   - **Use Case**: For data rarely accessed that can tolerate hours of retrieval latency, stored for at least 180 days.\n",
       "   - **Cost**: Lowest storage costs, but highest retrieval costs.\n",
       "   - **Ideal For**: Archival data, compliance, or historical data that doesn't require immediate access.\n",
       "\n",
       "Selecting the appropriate tier helps optimize costs based on how frequently you access your data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Explain the differences between hot, cool, cold and archive tier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "When choosing Azure Storage services, you generally pay for the following:\n",
       "\n",
       "1. **Storage Capacity**: The amount of data stored in GB or TB. Costs vary by tier—Hot is more expensive than Cool or Archive.\n",
       "\n",
       "2. **Data Access**: Charges for reading and writing data. Hot tier has lower access costs than Cool and Archive.\n",
       "\n",
       "3. **Data Retrieval**: Especially relevant for Archive tier, where retrieving data incurs higher costs.\n",
       "\n",
       "4. **Data Transfer**: Charges may apply for data transferred out of Azure data centers (egress).\n",
       "\n",
       "5. **Operations**: Number of read/write transactions.\n",
       "\n",
       "**Cost Example**:\n",
       "- **Hot Tier**: Storing 100 GB might cost $2/month, with lower transaction costs.\n",
       "- **Cool Tier**: Storing 100 GB might cost $1/month, but higher transaction costs.\n",
       "- **Archive Tier**: Storing 100 GB might cost $0.20/month, with high retrieval costs.\n",
       "\n",
       "Actual costs depend on Azure region and specific use case, so it's important to use the Azure Pricing Calculator for precise estimates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What is it that I'm paying for when choosing any of these services. Provide me with a cost example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "For Azure Storage access tiers, the minimum storage durations and consequences of early removal are as follows:\n",
       "\n",
       "1. **Hot Tier**:\n",
       "   - **Minimum Duration**: No minimum duration.\n",
       "   - **Early Removal**: No penalties; you can delete or move data anytime.\n",
       "\n",
       "2. **Cool Tier**:\n",
       "   - **Minimum Duration**: 30 days.\n",
       "   - **Early Removal**: If data is deleted or moved to a different tier before 30 days, you'll incur early deletion charges.\n",
       "\n",
       "3. **Cold Tier**:\n",
       "   - **Minimum Duration**: 90 days.\n",
       "   - **Early Removal**: Early deletion charges apply if data is removed or moved before 90 days.\n",
       "\n",
       "4. **Archive Tier**:\n",
       "   - **Minimum Duration**: 180 days.\n",
       "   - **Early Removal**: Early deletion charges apply if data is removed or moved before 180 days.\n",
       "\n",
       "Early deletion charges are designed to compensate for the lower cost of longer-term storage commitments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What is the minimum amount of time I should store the data in each of these tiers? What will happen if I remove the data earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Azure Archive Storage uses a mechanism optimized for long-term data storage with low access frequency, offering the lowest storage costs but with higher retrieval latency. Data in the Archive tier is stored in a way that requires several hours to retrieve, as it is designed for use cases where immediate access is not needed, such as compliance and archival purposes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What kind of mechanism is used for archive storage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wedebolsaz204stor.blob.core.windows.net/landing/videos/AZ-204 Day 1 - 71616-20241202_090658-Meeting Transcript.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A flat namespace in Azure Blob Storage means that all blobs are stored at the same level, without a hierarchical structure like traditional file systems. While Azure Blob Storage doesn't support folders in the traditional sense, you can simulate folder structures by including directory-like prefixes in blob names (e.g., \"folder1/file.txt\"). \n",
       "\n",
       "When you view blobs with these prefixes in tools like Azure Storage Explorer, they appear as folders, but in reality, they are just part of the blob's name. This approach allows you to organize blobs logically without creating actual folders."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What is a flat namespace? Can I create folders and what is the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A hierarchical namespace, like the one used in Azure Data Lake Storage Gen2, allows for a true directory structure, similar to traditional file systems. This enables features such as:\n",
       "\n",
       "1. **Directory Operations**: You can perform operations like renaming and deleting entire directories.\n",
       "\n",
       "2. **Access Control Lists (ACLs)**: Fine-grained permissions can be set at both the directory and file levels.\n",
       "\n",
       "3. **Efficient File Management**: Optimized for big data analytics, supporting operations like recursive file processing.\n",
       "\n",
       "In contrast, a flat namespace in Azure Blob Storage doesn't support these directory-level operations natively, as it treats all items as individual blobs without inherent parent-child relationships."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "How does this compare to a hierachical namespace?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage the Azure Blob storage lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/1-introduction\n",
      "https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/2-blob-storage-lifecycle\n",
      "https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/3-blob-storage-lifecycle-policies\n",
      "https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/4-add-policy-blob-storage\n",
      "https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/5-rehydrate-blob-data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " 'https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/\\n')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%learn\n",
    "https://learn.microsoft.com/en-us/training/modules/manage-azure-blob-storage-lifecycle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To move a blob from one access tier to another in C#, you can use the Azure.Storage.Blobs library. Here's a simple example:\n",
       "\n",
       "```csharp\n",
       "using Azure;\n",
       "using Azure.Storage.Blobs;\n",
       "using Azure.Storage.Blobs.Models;\n",
       "using System;\n",
       "using System.Threading.Tasks;\n",
       "\n",
       "class Program\n",
       "{\n",
       "    private static async Task Main(string[] args)\n",
       "    {\n",
       "        string connectionString = \"<your_connection_string>\";\n",
       "        string containerName = \"<your_container_name>\";\n",
       "        string blobName = \"<your_blob_name>\";\n",
       "\n",
       "        BlobServiceClient blobServiceClient = new BlobServiceClient(connectionString);\n",
       "        BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName);\n",
       "        BlobClient blobClient = containerClient.GetBlobClient(blobName);\n",
       "\n",
       "        try\n",
       "        {\n",
       "            // Set the blob's access tier to Cool\n",
       "            await blobClient.SetAccessTierAsync(AccessTier.Cool);\n",
       "            Console.WriteLine($\"Blob {blobName} has been moved to the Cool tier.\");\n",
       "        }\n",
       "        catch (RequestFailedException ex)\n",
       "        {\n",
       "            Console.WriteLine($\"Error: {ex.Message}\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `<your_connection_string>`, `<your_container_name>`, and `<your_blob_name>` with your actual Azure Storage connection string, container name, and blob name. This example changes the blob's access tier to Cool, but you can adjust the `AccessTier` to Hot, Cold, or Archive as needed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "How do I move a blob from one access tier to another? Share an example using C#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, you can automate the lifecycle of blobs in a storage account using a lifecycle management policy. Below is an example configuration in JSON that moves blobs to the Cool tier 30 days after their last modification and deletes them after 365 days.\n",
       "\n",
       "### JSON Configuration Example\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"rules\": [\n",
       "    {\n",
       "      \"name\": \"MoveToCoolAndDelete\",\n",
       "      \"enabled\": true,\n",
       "      \"type\": \"Lifecycle\",\n",
       "      \"definition\": {\n",
       "        \"filters\": {\n",
       "          \"blobTypes\": [\"blockBlob\"]\n",
       "        },\n",
       "        \"actions\": {\n",
       "          \"baseBlob\": {\n",
       "            \"tierToCool\": {\n",
       "              \"daysAfterModificationGreaterThan\": 30\n",
       "            },\n",
       "            \"delete\": {\n",
       "              \"daysAfterModificationGreaterThan\": 365\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  ]\n",
       "}\n",
       "```\n",
       "\n",
       "### Azure CLI Command\n",
       "\n",
       "To apply this policy using Azure CLI, save the JSON configuration to a file, for example `lifecycle-policy.json`, and run the following command:\n",
       "\n",
       "```bash\n",
       "az storage account management-policy create --account-name <your-storage-account-name> --resource-group <your-resource-group> --policy @lifecycle-policy.json\n",
       "```\n",
       "\n",
       "Replace `<your-storage-account-name>` and `<your-resource-group>` with your actual storage account name and resource group. The `@` symbol in the command indicates that the policy content is being loaded from a file."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Can I automate the lifecycle of blobs in a storage account? Share an example of such a configuration? Also include the AZ CLI command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Lifecycle management rules in Azure Blob Storage are automatically triggered based on the conditions specified in the policy, such as the age of the blobs. The rules typically run once a day to evaluate the conditions and apply actions like tier transitions or deletions based on the specified criteria (e.g., days since last modification)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "When are these rules triggered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In Azure Blob Storage lifecycle management, you can configure rules to:\n",
       "\n",
       "1. **Transition Blobs**: Move blobs between access tiers (e.g., Hot, Cool, Cold, Archive) based on conditions like days since last modification.\n",
       "\n",
       "2. **Delete Blobs**: Automatically delete blobs after a specified period.\n",
       "\n",
       "3. **Manage Snapshots and Versions**: Apply similar transition and deletion actions to blob snapshots and previous versions.\n",
       "\n",
       "Yes, it is possible to configure rules based on the last accessed property by enabling access tracking. You can use the `daysAfterLastAccessTimeGreaterThan` condition to apply actions based on the days since a blob was last accessed. However, note that access tracking needs to be enabled for the storage account to use this condition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What kind of rules can I configure? Is it possible to look for files that have a last accessed property?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Rehydration is the process of moving a blob from the Archive tier, where it is in a low-cost, offline state, to an online tier like Hot or Cool, so it can be accessed or modified.\n",
       "\n",
       "Here's a simple example in C# using Azure.Storage.Blobs to rehydrate a blob from the Archive tier to the Hot tier:\n",
       "\n",
       "```csharp\n",
       "using Azure;\n",
       "using Azure.Storage.Blobs;\n",
       "using Azure.Storage.Blobs.Models;\n",
       "using System;\n",
       "using System.Threading.Tasks;\n",
       "\n",
       "class Program\n",
       "{\n",
       "    private static async Task Main(string[] args)\n",
       "    {\n",
       "        string connectionString = \"<your_connection_string>\";\n",
       "        string containerName = \"<your_container_name>\";\n",
       "        string blobName = \"<your_blob_name>\";\n",
       "\n",
       "        BlobServiceClient blobServiceClient = new BlobServiceClient(connectionString);\n",
       "        BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName);\n",
       "        BlobClient blobClient = containerClient.GetBlobClient(blobName);\n",
       "\n",
       "        try\n",
       "        {\n",
       "            // Set the blob's access tier to Hot to rehydrate\n",
       "            await blobClient.SetAccessTierAsync(AccessTier.Hot);\n",
       "            Console.WriteLine($\"Blob {blobName} is being rehydrated to the Hot tier.\");\n",
       "        }\n",
       "        catch (RequestFailedException ex)\n",
       "        {\n",
       "            Console.WriteLine($\"Error: {ex.Message}\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `<your_connection_string>`, `<your_container_name>`, and `<your_blob_name>` with your actual Azure Storage connection string, container name, and blob name. This code changes the blob's access tier to Hot, initiating the rehydration process. Note that rehydration can take several hours to complete."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What is rehydration? Share an example on how to do this in C#."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Rehydrating a blob from the Archive tier to an online tier (Hot or Cool) can take several hours. The time depends on the rehydration priority:\n",
       "\n",
       "- **Standard Priority**: Typically takes up to 15 hours.\n",
       "- **High Priority**: Can complete in under 1 hour for blobs smaller than 10 GB.\n",
       "\n",
       "During rehydration:\n",
       "\n",
       "1. **Blob Remains Unavailable**: The blob cannot be accessed or modified until the rehydration process is complete.\n",
       "2. **Background Process**: The blob is moved from the offline storage in the Archive tier to the specified online tier.\n",
       "3. **Tier Indicator**: The blob's tier setting will still show as \"Archive\" until the rehydration is finished.\n",
       "\n",
       "Rehydration allows the blob to become accessible for read or write operations once it is in an online tier."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "How much time can it take to rehydrate from archive to another tier? What happens during this process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Archive tier in Azure Blob Storage uses low-cost, offline storage optimized for infrequent access with flexible latency requirements that can be on the order of hours. It is designed for long-term retention and cost efficiency, storing data in a way that minimizes costs compared to online storage tiers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What kind of storage is used for archive tier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with Azure Blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/1-introduction\n",
      "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/2-blob-storage-client-library-overview\n",
      "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/3-create-client-object\n",
      "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/4-develop-blob-storage-dotnet\n",
      "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/5-manage-container-properties-metadata-dotnet\n",
      "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/6-set-retrieve-properties-metadata-rest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('',\n",
       " 'https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/\\n')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%learn\n",
    "https://learn.microsoft.com/en-us/training/modules/work-azure-blob-storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Azure provides several SDKs to access Blob Storage, including:\n",
       "\n",
       "1. **.NET SDK**: For applications built using .NET languages like C#.\n",
       "2. **Java SDK**: For Java applications.\n",
       "3. **Python SDK**: For Python-based applications.\n",
       "4. **JavaScript/Node.js SDK**: For web and Node.js applications.\n",
       "5. **Go SDK**: For applications written in Go.\n",
       "6. **Ruby SDK**: For Ruby applications.\n",
       "7. **PHP SDK**: For PHP developers.\n",
       "\n",
       "These SDKs provide a convenient interface to interact with Azure Blob Storage for various programming environments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "What SDK's are available to access a blob storage account?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Below are examples of how to connect to an Azure Blob Storage account using both the account key and Microsoft Entra ID in Python.\n",
       "\n",
       "### Connect using the Account Key\n",
       "\n",
       "```python\n",
       "from azure.storage.blob import BlobServiceClient\n",
       "\n",
       "# Replace with your storage account information\n",
       "account_name = \"your_storage_account_name\"\n",
       "account_key = \"your_account_key\"\n",
       "\n",
       "# Create a BlobServiceClient using the account URL and account key\n",
       "blob_service_client = BlobServiceClient(\n",
       "    account_url=f\"https://{account_name}.blob.core.windows.net/\",\n",
       "    credential=account_key\n",
       ")\n",
       "\n",
       "# Example: List containers\n",
       "containers = blob_service_client.list_containers()\n",
       "for container in containers:\n",
       "    print(container['name'])\n",
       "```\n",
       "\n",
       "### Connect using Microsoft Entra ID (Azure Active Directory)\n",
       "\n",
       "```python\n",
       "from azure.identity import DefaultAzureCredential\n",
       "from azure.storage.blob import BlobServiceClient\n",
       "\n",
       "# Replace with your storage account name\n",
       "account_name = \"your_storage_account_name\"\n",
       "\n",
       "# Create a BlobServiceClient using the account URL and DefaultAzureCredential\n",
       "credential = DefaultAzureCredential()\n",
       "blob_service_client = BlobServiceClient(\n",
       "    account_url=f\"https://{account_name}.blob.core.windows.net/\",\n",
       "    credential=credential\n",
       ")\n",
       "\n",
       "# Example: List containers\n",
       "containers = blob_service_client.list_containers()\n",
       "for container in containers:\n",
       "    print(container['name'])\n",
       "```\n",
       "\n",
       "**Note**: When using Microsoft Entra ID, ensure that you have assigned the necessary roles to your Entra ID principal to access blob data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in Python on how to connect to a blob storage account using the account key and using a Microsoft Entra ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landing\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Replace with your storage account name\n",
    "account_name = \"wedebolsaz204stor\"\n",
    "\n",
    "# Create a BlobServiceClient using the account URL and DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{account_name}.blob.core.windows.net/\",\n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "# Example: List containers\n",
    "containers = blob_service_client.list_containers()\n",
    "for container in containers:\n",
    "    print(container['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is an example of how to create a container in an Azure Blob Storage account using Node.js.\n",
       "\n",
       "First, ensure you have installed the Azure Storage Blob SDK:\n",
       "\n",
       "```bash\n",
       "npm install @azure/storage-blob\n",
       "```\n",
       "\n",
       "### Node.js Example to Create a Container\n",
       "\n",
       "```javascript\n",
       "const { BlobServiceClient } = require('@azure/storage-blob');\n",
       "\n",
       "// Replace with your storage account connection string\n",
       "const connectionString = \"your_connection_string\";\n",
       "\n",
       "async function createContainer() {\n",
       "    // Create a BlobServiceClient from the connection string\n",
       "    const blobServiceClient = BlobServiceClient.fromConnectionString(connectionString);\n",
       "\n",
       "    // Specify a unique name for the container\n",
       "    const containerName = \"mynewcontainer\";\n",
       "\n",
       "    // Get a container client\n",
       "    const containerClient = blobServiceClient.getContainerClient(containerName);\n",
       "\n",
       "    try {\n",
       "        // Create the container\n",
       "        const createContainerResponse = await containerClient.create();\n",
       "        console.log(`Container created successfully.\\nRequest ID: ${createContainerResponse.requestId}`);\n",
       "    } catch (error) {\n",
       "        console.error(\"Error creating container:\", error.message);\n",
       "    }\n",
       "}\n",
       "\n",
       "createContainer().catch(console.error);\n",
       "```\n",
       "\n",
       "Replace `\"your_connection_string\"` with your actual Azure Blob Storage connection string. This script connects to your storage account and creates a new container named \"mynewcontainer\". Make sure the container name is unique within your storage account."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in Node.JS on how create a container in a blob storage account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Below is an example of how to set metadata on a container in Azure Blob Storage using Ruby.\n",
       "\n",
       "First, ensure you have the Azure Storage Blob gem installed:\n",
       "\n",
       "```bash\n",
       "gem install azure-storage-blob\n",
       "```\n",
       "\n",
       "### Ruby Example to Set Metadata on a Container\n",
       "\n",
       "```ruby\n",
       "require 'azure/storage/blob'\n",
       "\n",
       "# Replace with your storage account information\n",
       "account_name = 'your_storage_account_name'\n",
       "account_key = 'your_account_key'\n",
       "\n",
       "# Create a BlobServiceClient\n",
       "blob_service_client = Azure::Storage::Blob::BlobService.create(\n",
       "  storage_account_name: account_name,\n",
       "  storage_access_key: account_key\n",
       ")\n",
       "\n",
       "# Specify the container name\n",
       "container_name = 'your-container-name'\n",
       "\n",
       "# Metadata to set\n",
       "metadata = { 'key1' => 'value1', 'key2' => 'value2' }\n",
       "\n",
       "begin\n",
       "  # Set metadata on the container\n",
       "  blob_service_client.set_container_metadata(container_name, metadata)\n",
       "  puts \"Metadata set successfully on container: #{container_name}\"\n",
       "rescue Azure::Core::Http::HTTPError => e\n",
       "  puts \"Error setting metadata: #{e.message}\"\n",
       "end\n",
       "```\n",
       "\n",
       "Replace `'your_storage_account_name'`, `'your_account_key'`, and `'your-container-name'` with your actual Azure Blob Storage account details and container name. This script sets metadata key-value pairs on the specified container."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in Ruby on how to set metadata key/value on the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To retrieve metadata from a container using HTTP REST, you need to make a GET request with the appropriate headers. Here’s a step-by-step example:\n",
       "\n",
       "### HTTP REST Request to Retrieve Container Metadata\n",
       "\n",
       "1. **Prepare the Request**:\n",
       "\n",
       "   - **Method**: GET\n",
       "   - **URL**: `https://<your_storage_account>.blob.core.windows.net/<container_name>?restype=container`\n",
       "   - **Headers**:\n",
       "     - `x-ms-version`: Set to a valid Azure Storage Service version (e.g., `2020-08-04`).\n",
       "     - `Authorization`: Constructed using your account key.\n",
       "     - `x-ms-date`: The current UTC date and time.\n",
       "\n",
       "2. **Example Request (using cURL)**:\n",
       "\n",
       "```bash\n",
       "curl -X GET \\\n",
       "  -H \"x-ms-version: 2020-08-04\" \\\n",
       "  -H \"x-ms-date: <current_date_in_UTC>\" \\\n",
       "  -H \"Authorization: SharedKey <your_storage_account>:<signature>\" \\\n",
       "  \"https://<your_storage_account>.blob.core.windows.net/<container_name>?restype=container\"\n",
       "```\n",
       "\n",
       "### Steps to Construct the Authorization Header\n",
       "\n",
       "1. **Create the String to Sign**:\n",
       "   - Include HTTP method, headers, and resource information.\n",
       "\n",
       "2. **Compute the Signature**:\n",
       "   - Use HMAC-SHA256 with your account key.\n",
       "\n",
       "3. **Construct the Authorization Header**:\n",
       "   - Format as `SharedKey <your_storage_account>:<computed_signature>`.\n",
       "\n",
       "### Response\n",
       "\n",
       "The response will include HTTP headers for metadata in the format `x-ms-meta-name:value`. Metadata headers will be part of the response headers, and no response body is returned for this operation.\n",
       "\n",
       "### Note\n",
       "\n",
       "For security reasons, ensure that you handle your account keys and signatures securely. Also, use HTTPS to encrypt requests and responses."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example using HTTP Rest on how to retrieve the metadata from the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is an example of how to upload a blob to a container using C# with the Azure.Storage.Blobs library.\n",
       "\n",
       "First, ensure you have the Azure Storage Blob package installed:\n",
       "\n",
       "```bash\n",
       "dotnet add package Azure.Storage.Blobs\n",
       "```\n",
       "\n",
       "### C# Example to Upload a Blob to a Container\n",
       "\n",
       "```csharp\n",
       "using Azure.Storage.Blobs;\n",
       "using System;\n",
       "using System.IO;\n",
       "using System.Threading.Tasks;\n",
       "\n",
       "class Program\n",
       "{\n",
       "    private static async Task Main(string[] args)\n",
       "    {\n",
       "        // Replace with your storage account connection string\n",
       "        string connectionString = \"YourConnectionString\";\n",
       "\n",
       "        // Replace with your container name and blob name\n",
       "        string containerName = \"your-container-name\";\n",
       "        string blobName = \"your-blob-name\";\n",
       "        \n",
       "        // Path to the local file to upload\n",
       "        string filePath = \"path/to/your/file.txt\";\n",
       "\n",
       "        // Create a BlobServiceClient\n",
       "        BlobServiceClient blobServiceClient = new BlobServiceClient(connectionString);\n",
       "\n",
       "        // Get a reference to a container\n",
       "        BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName);\n",
       "\n",
       "        // Get a reference to a blob\n",
       "        BlobClient blobClient = containerClient.GetBlobClient(blobName);\n",
       "\n",
       "        try\n",
       "        {\n",
       "            // Upload the file to the blob\n",
       "            using FileStream uploadFileStream = File.OpenRead(filePath);\n",
       "            await blobClient.UploadAsync(uploadFileStream, true);\n",
       "            uploadFileStream.Close();\n",
       "\n",
       "            Console.WriteLine($\"Blob '{blobName}' uploaded to container '{containerName}'.\");\n",
       "        }\n",
       "        catch (Exception ex)\n",
       "        {\n",
       "            Console.WriteLine($\"Error: {ex.Message}\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `\"YourConnectionString\"`, `\"your-container-name\"`, `\"your-blob-name\"`, and `\"path/to/your/file.txt\"` with your actual Azure Storage connection string, container name, blob name, and file path, respectively. This code uploads a file to a blob within the specified container."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in C# on how to upload a blob to a container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is an example of how to download a blob from a container using Java with the Azure Storage Blob library.\n",
       "\n",
       "First, ensure you have the Azure Storage Blob SDK included in your project. If you're using Maven, add the following dependency to your `pom.xml`:\n",
       "\n",
       "```xml\n",
       "<dependency>\n",
       "    <groupId>com.azure</groupId>\n",
       "    <artifactId>azure-storage-blob</artifactId>\n",
       "    <version>12.14.0</version>\n",
       "</dependency>\n",
       "```\n",
       "\n",
       "### Java Example to Download a Blob from a Container\n",
       "\n",
       "```java\n",
       "import com.azure.storage.blob.BlobClient;\n",
       "import com.azure.storage.blob.BlobClientBuilder;\n",
       "import java.io.FileOutputStream;\n",
       "import java.io.IOException;\n",
       "\n",
       "public class BlobDownloadExample {\n",
       "\n",
       "    public static void main(String[] args) {\n",
       "        // Replace with your storage account connection string\n",
       "        String connectionString = \"your_connection_string\";\n",
       "\n",
       "        // Replace with your container name and blob name\n",
       "        String containerName = \"your-container-name\";\n",
       "        String blobName = \"your-blob-name\";\n",
       "\n",
       "        // Path where you want to save the downloaded file\n",
       "        String downloadFilePath = \"path/to/downloaded/file.txt\";\n",
       "\n",
       "        // Create a BlobClient\n",
       "        BlobClient blobClient = new BlobClientBuilder()\n",
       "                .connectionString(connectionString)\n",
       "                .containerName(containerName)\n",
       "                .blobName(blobName)\n",
       "                .buildClient();\n",
       "\n",
       "        try {\n",
       "            // Download the blob to a local file\n",
       "            blobClient.download(new FileOutputStream(downloadFilePath));\n",
       "            System.out.println(\"Blob downloaded successfully to \" + downloadFilePath);\n",
       "        } catch (IOException e) {\n",
       "            System.out.println(\"Error downloading blob: \" + e.getMessage());\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `\"your_connection_string\"`, `\"your-container-name\"`, `\"your-blob-name\"`, and `\"path/to/downloaded/file.txt\"` with your Azure Storage connection string, container name, blob name, and the path where you want to save the file, respectively. This code downloads the specified blob to a local file."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in Java on how to download the blob from the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is an example of how to set metadata on a blob using C# with the Azure.Storage.Blobs library.\n",
       "\n",
       "First, ensure you have the Azure Storage Blob package installed:\n",
       "\n",
       "```bash\n",
       "dotnet add package Azure.Storage.Blobs\n",
       "```\n",
       "\n",
       "### C# Example to Set Metadata on a Blob\n",
       "\n",
       "```csharp\n",
       "using Azure.Storage.Blobs;\n",
       "using Azure.Storage.Blobs.Models;\n",
       "using System;\n",
       "using System.Collections.Generic;\n",
       "using System.Threading.Tasks;\n",
       "\n",
       "class Program\n",
       "{\n",
       "    private static async Task Main(string[] args)\n",
       "    {\n",
       "        // Replace with your storage account connection string\n",
       "        string connectionString = \"YourConnectionString\";\n",
       "\n",
       "        // Replace with your container name and blob name\n",
       "        string containerName = \"your-container-name\";\n",
       "        string blobName = \"your-blob-name\";\n",
       "\n",
       "        // Create a BlobServiceClient\n",
       "        BlobServiceClient blobServiceClient = new BlobServiceClient(connectionString);\n",
       "\n",
       "        // Get a reference to a container\n",
       "        BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName);\n",
       "\n",
       "        // Get a reference to a blob\n",
       "        BlobClient blobClient = containerClient.GetBlobClient(blobName);\n",
       "\n",
       "        // Define metadata to set\n",
       "        IDictionary<string, string> metadata = new Dictionary<string, string>\n",
       "        {\n",
       "            { \"key1\", \"value1\" },\n",
       "            { \"key2\", \"value2\" }\n",
       "        };\n",
       "\n",
       "        try\n",
       "        {\n",
       "            // Set the metadata on the blob\n",
       "            await blobClient.SetMetadataAsync(metadata);\n",
       "\n",
       "            Console.WriteLine($\"Metadata set successfully on blob '{blobName}'.\");\n",
       "        }\n",
       "        catch (Exception ex)\n",
       "        {\n",
       "            Console.WriteLine($\"Error: {ex.Message}\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `\"YourConnectionString\"`, `\"your-container-name\"`, and `\"your-blob-name\"` with your actual Azure Storage connection string, container name, and blob name. This code sets metadata key-value pairs on the specified blob."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in C# on how to set metadata key/value on the blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Below is an example of how to delete a blob using C# with the Azure.Storage.Blobs library.\n",
       "\n",
       "First, ensure you have the Azure Storage Blob package installed:\n",
       "\n",
       "```bash\n",
       "dotnet add package Azure.Storage.Blobs\n",
       "```\n",
       "\n",
       "### C# Example to Delete a Blob\n",
       "\n",
       "```csharp\n",
       "using Azure.Storage.Blobs;\n",
       "using System;\n",
       "using System.Threading.Tasks;\n",
       "\n",
       "class Program\n",
       "{\n",
       "    private static async Task Main(string[] args)\n",
       "    {\n",
       "        // Replace with your storage account connection string\n",
       "        string connectionString = \"YourConnectionString\";\n",
       "\n",
       "        // Replace with your container name and blob name\n",
       "        string containerName = \"your-container-name\";\n",
       "        string blobName = \"your-blob-name\";\n",
       "\n",
       "        // Create a BlobServiceClient\n",
       "        BlobServiceClient blobServiceClient = new BlobServiceClient(connectionString);\n",
       "\n",
       "        // Get a reference to a container\n",
       "        BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName);\n",
       "\n",
       "        // Get a reference to a blob\n",
       "        BlobClient blobClient = containerClient.GetBlobClient(blobName);\n",
       "\n",
       "        try\n",
       "        {\n",
       "            // Delete the blob\n",
       "            await blobClient.DeleteIfExistsAsync();\n",
       "            Console.WriteLine($\"Blob '{blobName}' deleted successfully from container '{containerName}'.\");\n",
       "        }\n",
       "        catch (Exception ex)\n",
       "        {\n",
       "            Console.WriteLine($\"Error deleting blob: {ex.Message}\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `\"YourConnectionString\"`, `\"your-container-name\"`, and `\"your-blob-name\"` with your actual Azure Storage connection string, container name, and blob name. This code deletes the specified blob from the container. The `DeleteIfExistsAsync` method ensures that the operation does not throw an error if the blob doesn't exist."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in C# on how to delete a blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Below is an example of how to delete a container using C# with the Azure.Storage.Blobs library.\n",
       "\n",
       "First, ensure you have the Azure Storage Blob package installed:\n",
       "\n",
       "```bash\n",
       "dotnet add package Azure.Storage.Blobs\n",
       "```\n",
       "\n",
       "### C# Example to Delete a Container\n",
       "\n",
       "```csharp\n",
       "using Azure.Storage.Blobs;\n",
       "using System;\n",
       "using System.Threading.Tasks;\n",
       "\n",
       "class Program\n",
       "{\n",
       "    private static async Task Main(string[] args)\n",
       "    {\n",
       "        // Replace with your storage account connection string\n",
       "        string connectionString = \"YourConnectionString\";\n",
       "\n",
       "        // Replace with your container name\n",
       "        string containerName = \"your-container-name\";\n",
       "\n",
       "        // Create a BlobServiceClient\n",
       "        BlobServiceClient blobServiceClient = new BlobServiceClient(connectionString);\n",
       "\n",
       "        // Get a reference to a container\n",
       "        BlobContainerClient containerClient = blobServiceClient.GetBlobContainerClient(containerName);\n",
       "\n",
       "        try\n",
       "        {\n",
       "            // Delete the container\n",
       "            await containerClient.DeleteIfExistsAsync();\n",
       "            Console.WriteLine($\"Container '{containerName}' deleted successfully.\");\n",
       "        }\n",
       "        catch (Exception ex)\n",
       "        {\n",
       "            Console.WriteLine($\"Error deleting container: {ex.Message}\");\n",
       "        }\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "Replace `\"YourConnectionString\"` and `\"your-container-name\"` with your actual Azure Storage connection string and container name. This code deletes the specified container, and the `DeleteIfExistsAsync` method ensures that the operation does not throw an error if the container doesn't exist."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%question\n",
    "Share an example in C# on how to delete the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
